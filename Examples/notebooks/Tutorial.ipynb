{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# brainrender Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you will be shown the main functionalities of brainrender, but if you want to dive deeper into the various options available you can check out the other examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by adding the current path to sys.path to make sure that the imports work correctly\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "\n",
    "# Set up VTKPLOTTER to work in Jupyter notebooks\n",
    "from vtkplotter import *\n",
    "embedWindow(backend=False) \n",
    "\n",
    "# Imports from brainrender\n",
    "from brainrender.scene import Scene\n",
    "from brainrender.atlases.aba import ABA\n",
    "\n",
    "# Before populating the scene, we need to change the current working directory to the parent folder, \n",
    "# then we are ready to start!\n",
    "os.chdir(os.path.normpath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering brain regions\n",
    "To add brain regions to our scene, we can use the \"add_brain_regions\" function. \n",
    "To spicy which brain regions to render, we pass a list of strings, each of which is the acronym that corresponds to the brain region of interest.\n",
    "\n",
    "When you're rendering a brain region for the first time, brainrender will download the corresponding .obj file from the Allen API and stores it in the Data folder. Note: this requires an internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Brain render allows for the creation of a \"scene\" in which to render a \n",
    "    number of 3d objects (e.g. brain structures, neurons reconstructions etc.)\n",
    "    so we first need to import the class Scene and create an instance of it, \n",
    "    then we can add objects (\"actors\") to it. \n",
    "\"\"\"\n",
    "\n",
    "# Let's create our first scene!\n",
    "tutorial_scene = Scene(jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tutorial_scene.add_brain_regions(['MOs', 'MOp'], colors='red') # Add brain regions to the scene\n",
    "# brainrender will download a .obj file the first you render a region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will render the scene in a new window. \n",
    "# Press 'Esc' to close it.\n",
    "tutorial_scene.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know which brain structures are supported and what their acronyms here, you can print the list\n",
    "of available structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_scene.print_structures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also render multiple brain regions and only color the ones we are interested:\n",
    "# create a new scene\n",
    "tutorial_scene = Scene(jupyter=True)\n",
    "# display multiple regions and color the \"VIP\" regions\n",
    "tutorial_scene.add_brain_regions(['CA1', 'ZI', 'MOs'], colors='green', VIP_regions=['MOs'], VIP_color='red') \n",
    "tutorial_scene.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering neurons\n",
    "brainrender let's you render neurons reconstructed by the Mouse Light project from Janelia. \n",
    "If you have already downloaded neurons data from the Neurons Browser, go ahead and use the .json or .swc files you've got directly in brainrender. Otherwise, brainrender also let's you download the data directly (see Neurons example).\n",
    "\n",
    "You can find a couple example files in \"Examples/example_files\" to get you started,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the filepath of the JSON file\n",
    "neurons_file = \"Examples/example_files/one_neuron.json\"\n",
    "\n",
    "# Get the Mouse Light data loader function\n",
    "from brainrender.Utils.parsers.mouselight import NeuronsParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When rendering neurons you have many options to choose how to color them. For more detailes check out the example on Neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the actors for the neurons to render\n",
    "tutorial_scene = Scene(jupyter=True)\n",
    "parser = NeuronsParser(scene=tutorial_scene, \n",
    "                            color_neurites=True, axon_color=\"antiquewhite\", \n",
    "                            soma_color=\"darkgoldenrod\", dendrites_color=\"firebrick\")\n",
    "neurons, _ = parser.render_neurons(neurons_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then use the \"add_neurons\" function  to add the neurons to the scene (and don't forget to render it!)\n",
    "tutorial_scene.add_neurons(neurons)\n",
    "tutorial_scene.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And you can show neurons and brain structures in the same scene to get a better understanding of where these beautiful axons go:\n",
    "tutorial_scene = Scene(jupyter=True)\n",
    "tutorial_scene.add_neurons(neurons)\n",
    "tutorial_scene.add_brain_regions(['ZI'], colors='white', alpha=0.5) # add the ZonaIncerta to our scene\n",
    "tutorial_scene.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should look something like this (here for the visual cortex):\n",
    "<img src=\"../Docs/Media/neuron.png\" width=\"600\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering connectivity data\n",
    "brainrender can be used to render tractography data downloaded from the Allen Brain Atlas mouse Connectome Database.\n",
    "These data show afferent projections to a point of interest. \n",
    "Given a brain region of interest, we can download data from experiments whose injections showed projections to our brain region. Then we can render these projections in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This kind of interctions with the Allen Brain Atlas datasets are handled by the class called ABA\n",
    "from brainrender.atlases.aba import ABA\n",
    "analyzer = ABA()\n",
    "tutorial_scene = Scene(jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the projections to the Zona Incerta\n",
    "# First, get a point within the zona incerta\n",
    "p0 = tutorial_scene.get_region_CenterOfMass(\"ZI\")\n",
    "# Then, use these coordinates to fetch tractography data\n",
    "tract = analyzer.get_projection_tracts_to_target(p0=p0) # <- this might take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new scene. Add the projections, the mesh for the ZI and render the scene. \n",
    "tutorial_scene.add_brain_regions(['ZI'], colors='red', alpha=.5) # add the PAG to our scene\n",
    "tutorial_scene.add_tractography(tract, display_injection_structure=False, color_by=\"region\")\n",
    "tutorial_scene.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results should look something like this (here for the visual cortex):\n",
    "<img src=\"../Docs/Media/tractography.png\" width=\"600\" height=\"350\">\n",
    "\n",
    "### Rendering streamlines.\n",
    "brainrender also lets you visualize efferent projections from a region of interest as streamlines.\n",
    "Head over to the streamlines tutorial to see how to render streamlines data. \n",
    "<img src=\"../Docs/Media/streamlines2.png\" width=\"600\" height=\"350\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to check the other examples to lear more about how to use brainrender to make amazing 3D renderings!\n",
    "Also, you can find a list of variables you can play around with in brainrender.variables.py\n",
    "Playing around with these variables will allow you to make the rendering look exactly how you want them to be."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}